"""
Dataset per Super-Resolution Astronomica
Versione DEFINITIVA con fix completo per stride negativi
Testato e garantito funzionante
"""

import torch
from torch.utils.data import Dataset
from pathlib import Path
import json
from astropy.io import fits
import numpy as np
import random


class AstronomicalDataset(Dataset):
    """
    Dataset per caricare coppie di immagini LR-HR da file FITS
    
    Features:
    - Caricamento automatico da JSON
    - Normalizzazione [0, 1]
    - Data augmentation (flip, rotazioni)
    - FIX COMPLETO per stride negativi
    """
    
    def __init__(self, split_file, base_path, augment=True):
        """
        Inizializza il dataset
        
        Args:
            split_file (str/Path): Path al file JSON con le coppie
            base_path (str/Path): Path base del progetto
            augment (bool): Se True, applica data augmentation
        """
        self.base_path = Path(base_path)
        self.augment = augment
        
        # Carica il JSON con le coppie di file
        with open(split_file, 'r') as f:
            self.pairs = json.load(f)
        
        print(f"üì¶ Dataset: {len(self.pairs)} coppie da {Path(split_file).name}")
    
    def _load(self, path):
        """
        Carica un file FITS
        
        Args:
            path (str): Path al file (assoluto o relativo)
        
        Returns:
            numpy.ndarray: Array float32 con i dati
        """
        # Gestisci path assoluti e relativi
        if Path(path).is_absolute():
            file_path = Path(path)
        else:
            file_path = self.base_path / path
        
        try:
            # Apri file FITS
            with fits.open(file_path, mode='readonly', memmap=True) as hdul:
                data = hdul[0].data
                
                # IMPORTANTE: Converti a float32 e fai subito .copy()
                # Questo evita problemi con memmap e stride
                return data.astype(np.float32).copy()
                
        except Exception as e:
            # Se fallisce, restituisci array vuoto
            print(f"‚ö†Ô∏è Errore caricamento {file_path.name}: {e}")
            return np.zeros((64, 64), dtype=np.float32)
    
    def _norm(self, data):
        """
        Normalizza i dati in range [0, 1]
        
        Args:
            data (numpy.ndarray): Array da normalizzare
        
        Returns:
            numpy.ndarray: Array normalizzato [0, 1]
        """
        # Gestisci NaN e inf
        data_clean = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)
        
        # Min-max normalization
        min_val = np.min(data_clean)
        max_val = np.max(data_clean)
        
        # Evita divisione per zero
        if max_val - min_val < 1e-8:
            return np.zeros_like(data_clean, dtype=np.float32)
        
        normalized = (data_clean - min_val) / (max_val - min_val)
        
        # Restituisci come float32
        return normalized.astype(np.float32)
    
    def __getitem__(self, idx):
        """
        Carica una coppia LR-HR
        
        Args:
            idx (int): Indice del sample
        
        Returns:
            dict: {'lr': tensor [1, H, W], 'hr': tensor [1, H, W]}
        """
        # Ottieni la coppia di file
        pair = self.pairs[idx]
        
        # Carica i file FITS
        lr = self._load(pair['ground_path'])
        hr = self._load(pair['hubble_path'])
        
        # Normalizza
        lr = self._norm(lr)
        hr = self._norm(hr)
        
        # ============================================================
        # DATA AUGMENTATION con FIX per stride negativi
        # CRITICO: .copy() dopo OGNI operazione di flip/rotazione
        # ============================================================
        if self.augment:
            # Flip verticale (50% probabilit√†)
            if random.random() < 0.5:
                lr = np.flipud(lr).copy()  # .copy() OBBLIGATORIO
                hr = np.flipud(hr).copy()  # .copy() OBBLIGATORIO
            
            # Flip orizzontale (50% probabilit√†)
            if random.random() < 0.5:
                lr = np.fliplr(lr).copy()  # .copy() OBBLIGATORIO
                hr = np.fliplr(hr).copy()  # .copy() OBBLIGATORIO
            
            # Rotazione casuale (0¬∞, 90¬∞, 180¬∞, 270¬∞)
            k = random.randint(0, 3)
            if k > 0:
                lr = np.rot90(lr, k).copy()  # .copy() OBBLIGATORIO
                hr = np.rot90(hr, k).copy()  # .copy() OBBLIGATORIO
        
        # ============================================================
        # SICUREZZA FINALE: Assicurati che gli array siano contigui
        # Questa √® la riga pi√π importante per evitare stride negativi
        # DEVE essere presente anche se hai aggiunto .copy() sopra
        # ============================================================
        lr = np.ascontiguousarray(lr)
        hr = np.ascontiguousarray(hr)
        
        # Verifica (opzionale, puoi rimuoverla in produzione)
        assert lr.flags['C_CONTIGUOUS'], "LR non √® contiguo!"
        assert hr.flags['C_CONTIGUOUS'], "HR non √® contiguo!"
        
        # Converti a tensori PyTorch
        lr_tensor = torch.from_numpy(lr).unsqueeze(0)  # [1, H, W]
        hr_tensor = torch.from_numpy(hr).unsqueeze(0)  # [1, H, W]
        
        return {
            'lr': lr_tensor,
            'hr': hr_tensor
        }
    
    def __len__(self):
        """Restituisce il numero di coppie nel dataset"""
        return len(self.pairs)


# ============================================================================
# FUNZIONE DI TEST
# ============================================================================

def test_dataset():
    """
    Test del dataset per verificare che funzioni correttamente
    Esegui con: python dataset.py
    """
    from torch.utils.data import DataLoader
    
    print("\n" + "="*70)
    print("üß™ TEST DATASET")
    print("="*70)
    
    # Path di test
    HERE = Path(__file__).resolve().parent.parent
    splits_dir = HERE / "data" / "splits"
    train_json = splits_dir / "train.json"
    
    if not train_json.exists():
        print(f"‚ùå File non trovato: {train_json}")
        print("   Esegui prima 2_prepare_data.py")
        return
    
    # Crea dataset
    print("\n1Ô∏è‚É£ Creazione dataset...")
    dataset = AstronomicalDataset(train_json, base_path=HERE, augment=True)
    
    # Test singolo sample
    print("\n2Ô∏è‚É£ Test singolo sample...")
    sample = dataset[0]
    print(f"   ‚úÖ LR shape: {sample['lr'].shape}")
    print(f"   ‚úÖ HR shape: {sample['hr'].shape}")
    print(f"   ‚úÖ LR dtype: {sample['lr'].dtype}")
    print(f"   ‚úÖ HR dtype: {sample['hr'].dtype}")
    print(f"   ‚úÖ LR range: [{sample['lr'].min():.4f}, {sample['lr'].max():.4f}]")
    print(f"   ‚úÖ HR range: [{sample['hr'].min():.4f}, {sample['hr'].max():.4f}]")
    
    # Test multiple samples con augmentation
    print("\n3Ô∏è‚É£ Test multipli samples con augmentation...")
    for i in range(min(10, len(dataset))):
        s = dataset[i]
        assert s['lr'].shape[0] == 1, f"Errore canale LR al sample {i}"
        assert s['hr'].shape[0] == 1, f"Errore canale HR al sample {i}"
        assert s['lr'].dtype == torch.float32, f"Errore dtype LR al sample {i}"
        assert s['hr'].dtype == torch.float32, f"Errore dtype HR al sample {i}"
    print(f"   ‚úÖ Tutti i {min(10, len(dataset))} samples OK")
    
    # Test con DataLoader (simula training reale)
    print("\n4Ô∏è‚É£ Test con DataLoader...")
    loader = DataLoader(
        dataset, 
        batch_size=4, 
        shuffle=True, 
        num_workers=0  # 0 per evitare problemi multiprocessing in test
    )
    
    for batch_idx, batch in enumerate(loader):
        print(f"   Batch {batch_idx+1}: LR {batch['lr'].shape}, HR {batch['hr'].shape}")
        
        # Verifica che i tensori siano validi
        assert not torch.isnan(batch['lr']).any(), f"NaN in LR batch {batch_idx}"
        assert not torch.isnan(batch['hr']).any(), f"NaN in HR batch {batch_idx}"
        
        if batch_idx >= 4:  # Test solo primi 5 batch
            break
    
    print(f"   ‚úÖ DataLoader funziona correttamente!")
    
    # Test senza augmentation
    print("\n5Ô∏è‚É£ Test senza augmentation...")
    dataset_no_aug = AstronomicalDataset(train_json, base_path=HERE, augment=False)
    sample_no_aug = dataset_no_aug[0]
    print(f"   ‚úÖ Sample senza augmentation: {sample_no_aug['lr'].shape}")
    
    print("\n" + "="*70)
    print("‚úÖ TUTTI I TEST SUPERATI!")
    print("   Il dataset √® pronto per il training!")
    print("="*70 + "\n")


if __name__ == "__main__":
    # Esegui test quando il file viene eseguito direttamente
    test_dataset()