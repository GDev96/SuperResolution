# Astro Super-Resolution Pipeline

Pipeline completa per la super-risoluzione di immagini astronomiche utilizzando Deep Learning. Il sistema combina dati di telescopi terrestri con immagini Hubble per addestrare modelli di upscaling avanzati.

## ğŸ“‹ Indice

- [Panoramica](#-panoramica)
- [Struttura del Progetto](#-struttura-del-progetto)
- [Requisiti](#-requisiti)
- [Installazione](#-installazione)
- [Architettura dei Modelli](#-architettura-dei-modelli)
- [Pipeline Completa](#-pipeline-completa)
- [Configurazione Hardware](#-configurazione-hardware)
- [Troubleshooting](#-troubleshooting)
- [Risultati Attesi](#-risultati-attesi)
- [Riferimenti](#-riferimenti)

## ğŸŒŒ Panoramica

Questa pipeline trasforma immagini astronomiche a bassa risoluzione in output ad alta risoluzione attraverso:

- **Astrometric Solving**: Calibrazione WCS con ASTAP
- **Image Registration**: Allineamento spaziale tramite riproiezione
- **Patch Extraction**: Estrazione di coppie LR-HR allineate WCS-aware
- **Deep Learning**: Addestramento di modelli ibridi (RRDB + HAT)
- **Inference Scientifica**: Generazione TIFF 16-bit per analisi

## ğŸ“ Struttura del Progetto

```
SuperResolution/
â”œâ”€â”€ data/                          # Dataset organizzati per target
â”‚   â””â”€â”€ M42/                       # Esempio: Nebulosa di Orione
â”‚       â”œâ”€â”€ 1_originarie/
â”‚       â”‚   â”œâ”€â”€ local_raw/         # Immagini osservatorio grezze
â”‚       â”‚   â””â”€â”€ img_lights/        # Immagini Hubble grezze
â”‚       â”œâ”€â”€ 2_solved_astap/        # Output ASTAP (WCS calibrato)
â”‚       â”œâ”€â”€ 3_registered_native/   # Immagini riproiettate
â”‚       â”œâ”€â”€ 4_quality_check/       # Overlay di controllo
â”‚       â”œâ”€â”€ 6_patches_final/       # Coppie LR-HR estratte
â”‚       â”œâ”€â”€ 7_dataset_ready_LOG/   # Dataset normalizzato (TIFF 16-bit)
â”‚       â””â”€â”€ 8_dataset_split/       # JSON train/val/test
â”‚
â”œâ”€â”€ models/                        # Architetture esterne (CRITICHE)
â”‚   â”œâ”€â”€ BasicSR/                   # Repository BasicSR (RRDBNet)
â”‚   â”‚   â””â”€â”€ basicsr/archs/rrdbnet_arch.py
â”‚   â””â”€â”€ HAT/                       # Repository HAT (Hybrid Attention Transformer)
â”‚       â””â”€â”€ hat/archs/hat_arch.py
â”‚
â”œâ”€â”€ weights/                       # Pesi pre-addestrati (opzionali)
â”‚   â”œâ”€â”€ RRDB_pretrained.pth        # Pesi ImageNet per Stage 1
â”‚   â””â”€â”€ HAT_pretrained.pth         # Pesi pre-training HAT
â”‚
â”œâ”€â”€ outputs/                       # Risultati training/inference
â”‚   â””â”€â”€ M42_GPU_0/
â”‚       â”œâ”€â”€ checkpoints/
â”‚       â”‚   â”œâ”€â”€ best_model.pth     # Modello con PSNR migliore
â”‚       â”‚   â””â”€â”€ last.pth           # Ultimo checkpoint
â”‚       â”œâ”€â”€ tensorboard/           # Log TensorBoard
â”‚       â””â”€â”€ test_results_tiff/     # Output inferenza
â”‚
â”œâ”€â”€ scripts/                       # Pipeline scripts
â”‚   â”œâ”€â”€ Dataset_step1_datasetwcs.py      # Solving e Registrazione
â”‚   â”œâ”€â”€ Dataset_step2_mosaicHSTObs.py    # Controllo allineamento
â”‚   â”œâ”€â”€ Dataset_step3_extractpatches_Gaia.py  # Estrazione patch
â”‚   â”œâ”€â”€ Dataset_step4_normalization.py   # Normalizzazione LOG
â”‚   â”œâ”€â”€ Modello_1.py                     # Setup ambiente
â”‚   â”œâ”€â”€ Modello_2.py                     # Creazione split
â”‚   â”œâ”€â”€ Modello_3.py                     # Launcher training
â”‚   â”œâ”€â”€ Modello_4.py                     # Finalizzazione modello
â”‚   â”œâ”€â”€ Modello_5.py                     # Inferenza
â”‚   â””â”€â”€ Modello_supporto.py              # Worker training
â”‚
â””â”€â”€ src/                           # Moduli core
    â”œâ”€â”€ architecture.py            # Modello ibrido (RRDB+HAT)
    â”œâ”€â”€ dataset.py                 # Loader TIFF 16-bit
    â”œâ”€â”€ losses.py                  # Loss functions
    â”œâ”€â”€ metrics.py                 # PSNR/SSIM
    â””â”€â”€ env_setup.py               # Setup percorsi
```

## ğŸ”§ Requisiti

### Software

- Python 3.10+
- ASTAP (Astrometric Solver): [Download](https://www.hnsky.org/astap.htm)
- Database ASTAP D50: [Download](https://www.hnsky.org/astap.htm)
- CUDA 11.8+ (per GPU NVIDIA)

### Hardware Consigliato

- **GPU**: NVIDIA H100/H200 (141 GB VRAM) oppure RTX 4090/A100
- **RAM**: 64 GB+
- **Storage**: 500 GB+ SSD (per dataset grandi)

### Dipendenze Python

Ã¨ stato predisposto un requirements.txt specifico che scarica la versione CPU di PyTorch per risparmiare spazio.

```bash
pip install -r requirements.txt

```

## ğŸš€ Installazione

### 1. Setup Base

```bash
git clone <repository-url>
cd SuperResolution
```

#### Creazione e attivazione venv

# Crea il virtual environment
python -m venv venv

# Attiva l'ambiente
.\venv\Scripts\Activate.ps1

### 2. Installazione Modelli Esterni

I modelli BasicSR e HAT devono essere clonati nella cartella `models/`:

```bash
cd models

# BasicSR (per RRDBNet)
git clone https://github.com/XPixelGroup/BasicSR.git
cd BasicSR
pip install -e .
cd ..

# HAT (Hybrid Attention Transformer)
git clone https://github.com/XPixelGroup/HAT.git
cd HAT
pip install -r requirements.txt
cd ../..
```

**Verifica struttura**:

```
models/
â”œâ”€â”€ BasicSR/basicsr/archs/rrdbnet_arch.py  âœ“
â””â”€â”€ HAT/hat/archs/hat_arch.py              âœ“
```

### 3. Setup Ambiente Python

```bash
cd scripts
python Modello_1.py
```

Questo script:
- Installa PyTorch con supporto CUDA
- Configura tutte le dipendenze
- Verifica l'integritÃ  dell'ambiente

### 4. Installazione ASTAP

- **Windows**: Scarica l'installer da [hnsky.org](https://www.hnsky.org/astap.htm)
- **Linux**: `sudo apt install astap` (o compila da sorgente)

Il pipeline cerca ASTAP in:
- `C:\Program Files\astap\astap.exe`
- `C:\Program Files (x86)\astap\astap.exe`
- Path di sistema

## ğŸ§  Architettura dei Modelli

### Modello Ibrido (HybridSuperResolutionModel)

Il sistema utilizza una **architettura a due stadi**:

```
Input (128Ã—128)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: RRDBNet       â”‚  â† BasicSR (models/BasicSR)
â”‚  - 23 RRDB Blocks       â”‚
â”‚  - Upscale 2Ã— (â†’256px)  â”‚
â”‚  - Smoothing Layer      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: HAT           â”‚  â† HAT Transformer (models/HAT)
â”‚  - Hybrid Attention     â”‚
â”‚  - 6 Layers Ã— 6 Heads   â”‚
â”‚  - Upscale 2Ã— (â†’512px)  â”‚
â”‚  - Anti-Checkerboard    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (512Ã—512)
```

### Componenti Chiave

#### 1. RRDBNet (Stage 1)

- **Sorgente**: `models/BasicSR/basicsr/archs/rrdbnet_arch.py`
- **Funzione**: Estrazione features e primo upscale
- **Parametri**:
  - `num_feat=64`: Feature maps
  - `num_block=23`: Blocchi residui densi
  - `scale=2`: Fattore upscaling

#### 2. HAT (Stage 2)

- **Sorgente**: `models/HAT/hat/archs/hat_arch.py`
- **Funzione**: Raffinamento con Attention
- **Configurazione H200 (Memory-Safe)**:

```python
embed_dim=120        # Divisibile per num_heads=6
depths=[6,6,6,6,6,6] # 6 Transformer layers
window_size=16       # Attention window
```

#### 3. Anti-Checkerboard Layer

- Filtri Gaussiani per eliminare artefatti griglia
- ModalitÃ : 'light', 'balanced', 'strong'

### Loss Function (CombinedLoss)

```python
Total Loss = Î»â‚Â·Charbonnier + Î»â‚‚Â·Perceptual + Î»â‚ƒÂ·Astro
```

- **Charbonnier Loss**: L1 robusta (principale)
- **Perceptual Loss**: VGG19 feature space
- **Astro Loss**: Penalizza errori su stelle/strutture luminose

## ğŸ”„ Pipeline Completa

### FASE 1: Preparazione Dataset

#### Step 1: Astrometric Solving

```bash
python Dataset_step1_datasetwcs.py
```

**Cosa fa**:
- Cerca ASTAP nel sistema
- Risolve WCS per ogni immagine (coordinate celesti)
- Registra Hubble e Osservatorio su griglia comune
- Applica riproiezione via `reproject_interp`

**Input**:
- `data/M42/1_originarie/local_raw/*.fits` (Osservatorio)
- `data/M42/1_originarie/img_lights/*.fits` (Hubble)

**Output**:
- `data/M42/2_solved_astap/` (WCS calibrati)
- `data/M42/3_registered_native/` (Allineati)

**Configurazione FOV (se ASTAP fallisce)**:

```python
FORCE_FOV = 0.46  # Gradi (da adattare al telescopio)
USE_MANUAL_FOV = True
```

#### Step 2: Quality Check (Opzionale)

```bash
python Dataset_step2_mosaicHSTObs.py
```

Genera overlay RGB per verificare l'allineamento:
- **Verde**: Hubble
- **Magenta**: Osservatorio

**Output**: `data/M42/4_quality_check/M42_mosaic_check.png`

#### Step 3: Estrazione Patch

```bash
python Dataset_step3_extractpatches_Gaia.py
```

**Cosa fa**:
- Estrae patch sovrapposte da Hubble (512Ã—512)
- Riproietta Osservatorio su WCS allineato (128Ã—128)
- Genera coppie LR-HR con WCS identico
- Crea PNG di debug per validazione

**Parametri**:

```python
HR_SIZE = 512      # Dimensione patch Hubble
AI_LR_SIZE = 128   # Dimensione patch Osservatorio
STRIDE = 150       # Sovrapposizione patch
MIN_COVERAGE = 0.50  # % minima dati validi
```

**Output**:
- `data/M42/6_patches_final/pair_NNNNNN/`
  - `hubble.fits` (512Ã—512)
  - `observatory.fits` (128Ã—128)
- `data/M42/6_debug_visuals/` (prime 50 coppie)

#### Step 4: Normalizzazione LOG

```bash
python Dataset_step4_normalization.py
```

**Trasformazioni**:
- **Log Stretch**: `log(data + Îµ)` per comprimere dinamica
- **Percentile Clipping**: Taglia rumore e saturazioni
- **Espansione 16-bit**: Output TIFF (0-65535)

**Output**:
- `data/M42/7_dataset_ready_LOG/pair_NNNNNN/`
  - `hubble.tiff` (16-bit)
  - `observatory.tiff` (16-bit)

### FASE 2: Training del Modello

#### Step 1: Creazione Split

```bash
python Modello_2.py
```

Genera JSON per train/val/test (90/10 split):
- `data/M42/8_dataset_split/splits_json/train.json`
- `data/M42/8_dataset_split/splits_json/val.json`

#### Step 2: Configurazione Training

Modifica `Modello_3.py`:

```python
TARGET_NAME = "M42"  # Nome del target
NUM_GPUS = 1         # Numero GPU
```

#### Step 3: Avvio Training

```bash
python Modello_3.py
```

**Hyperparameters** (in `Modello_supporto.py`):

```python
BATCH_SIZE = 3          # Per H200 (141GB VRAM)
ACCUM_STEPS = 20        # Gradient Accumulation
LR = 4e-4               # Learning Rate
TOTAL_EPOCHS = 150
```

**Monitoraggio con TensorBoard**:

```bash
tensorboard --logdir=outputs/M42_GPU_0/tensorboard
```

**Metriche tracciate**:
- Loss totale e componenti (Charbonnier, Astro, Perceptual)
- PSNR/SSIM su validation set
- Learning rate
- Immagini di preview (ogni epoca)

#### Step 4: Finalizzazione

```bash
python Modello_4.py --target M42
```

Copia il best checkpoint in:
- `outputs/M42/final_weights/best.pth`

### FASE 3: Inferenza

```bash
python Modello_5.py
```

**Output**:
- `outputs/M42/test_results_tiff/tiff_science/` (TIFF 16-bit)
- `outputs/M42/test_results_tiff/png_preview/` (Comparazioni visive)

**Formato Output**:
- **TIFF Scientifici**: Range completo 16-bit per analisi
- **PNG Preview**: [LR_upscaled | SR | HR_ground_truth]

## âš™ï¸ Configurazione Hardware

### GPU NVIDIA H100/H200 (Consigliato)

**Configurazione Memory-Safe**:

```python
# architecture.py
embed_dim=120           # Ridotto da 180
depths=[6,6,6,6,6,6]   # 6 layers invece di 12
```

**Ottimizzazioni**:

```python
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True
PYTORCH_CUDA_ALLOC_CONF = "expandable_segments:True"
```

### RTX 4090 / A100 (Alternative)

Riduci batch size e accumulation steps:

```python
BATCH_SIZE = 1          # Invece di 3
ACCUM_STEPS = 60        # Invece di 20
```

### Multi-GPU Training

Modifica `Modello_3.py`:

```python
NUM_GPUS = 4  # Esempio: 4Ã— H100
```

Ogni GPU addestrerÃ  su uno split del dataset.

## ğŸ” Troubleshooting

### Problema: ASTAP non trova soluzioni

**Sintomo**: File `.fits` senza WCS dopo Step 1

**Soluzioni**:

1. Verifica FOV manuale:

```python
FORCE_FOV = 0.46  # Calcola: (altezza_sensore_mm / focale_mm) * (180/Ï€)
USE_MANUAL_FOV = True
```

2. Controlla header FITS:

```python
from astropy.io import fits
hdul = fits.open('image.fits')
print(hdul[0].header)  # Cerca FOCALLEN, XPIXSZ
```

### Problema: Patch completamente nere

**Sintomo**: Dataset vuoto o training loss = 0

**Soluzioni**:

1. Controlla normalizzazione:

```bash
python debugmodello.py
```

2. Verifica percentili:

```python
LOWER_PERCENTILE = 1.0   # Aumenta se troppo scuro
UPPER_PERCENTILE = 98.0  # Riduci per evidenziare faint objects
```

### Problema: RuntimeError (Mixed Precision)

**Sintomo**: `Expected tensor for argument to have the same type`

**Soluzione**: Conversione esplicita float32:

```python
# In Modello_supporto.py (giÃ  implementato)
metrics.update(v_pred.float(), v_hr.float())
```

### Problema: Import Error (BasicSR/HAT)

**Sintomo**: `ModuleNotFoundError: No module named 'basicsr'`

**Soluzioni**:

1. Verifica cartella `models/`:

```bash
ls -la models/BasicSR/basicsr/archs/rrdbnet_arch.py
ls -la models/HAT/hat/archs/hat_arch.py
```

2. Reinstalla:

```bash
cd models/BasicSR && pip install -e . && cd ../..
```

### Problema: Out of Memory (OOM)

**Sintomo**: `CUDA out of memory`

**Soluzioni**:

1. Riduci batch size:

```python
BATCH_SIZE = 1
```

2. Usa solo Stage 1 (disabilita HAT):

```python
# architecture.py
self.has_stage2 = False
```

3. Riduci dimensione patch:

```python
HR_SIZE = 256    # Invece di 512
AI_LR_SIZE = 64  # Invece di 128
```

## ğŸ“Š Risultati Attesi

### Metriche Target

| Metrica | Baseline (Bicubic) | Target Modello |
|---------|-------------------|----------------|
| PSNR    | ~28 dB            | 32-35 dB       |
| SSIM    | ~0.85             | 0.92-0.95      |

### Esempio Output

Input LR (128Ã—128) â†’ Output SR (512Ã—512) â†’ Ground Truth HR

- Dettagli stellari recuperati
- Nebulose con texture preservate
- Assenza di artefatti griglia

## ğŸ“š Riferimenti

### Modelli Utilizzati

- **RRDBNet**: ESRGAN Paper
  - Repository: [BasicSR](https://github.com/XPixelGroup/BasicSR)

- **HAT**: Hybrid Attention Transformer
  - Repository: [HAT Official](https://github.com/XPixelGroup/HAT)

### Dataset

- **Hubble Legacy Archive**: [HST Data](https://hla.stsci.edu/)
- **ASTAP**: [Astrometric Solver](https://www.hnsky.org/astap.htm)